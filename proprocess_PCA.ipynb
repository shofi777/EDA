{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "import scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 334)\n"
     ]
    }
   ],
   "source": [
    "path_daisee = ('C:/Users/hasegawa-lab-pc/OneDrive - Japan Advanced Institute of Science and Technology/Documents/Dataset/DAiSEE/OpenFace_2.2.0_win_x64/processed/csv/')\n",
    "path_emotiw = ('C:/Users/hasegawa-lab-pc/OneDrive - Japan Advanced Institute of Science and Technology/Documents/Dataset/EmotiW/Engagement recognition/01. Train and validation/')\n",
    "df_feat = pd.read_csv(path_daisee+'csv_train/181374016.csv') #Load a feature sample\n",
    "print(df_feat.shape)\n",
    "\n",
    "features31 = [5,6,7,8,9,10,11,12,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315]\n",
    "features311 = list(range(5,316))\n",
    "\n",
    "# REMOVE SPACES FROM COLUMN NAMES\n",
    "df = pd.DataFrame(df_feat)\n",
    "df.columns = df.columns.str.replace(' ','')\n",
    "\n",
    "#for num, col_name in enumerate(df.columns):\n",
    "#    print(num, col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(287, 311)\n"
     ]
    }
   ],
   "source": [
    "# SELECT DATA from TIMESTEPS between 0.5 to 9.5\n",
    "dfqr = df.query('(timestamp > 0.3) & (timestamp < 9.9)')\n",
    "# print(dfqr)\n",
    "\n",
    "# SELECT 31 FEATURES COLUMNS\n",
    "dfqr = dfqr.iloc[:,features311]\n",
    "print(dfqr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 311)\n",
      "(55, 311)\n",
      "(55, 311)\n",
      "(55, 311)\n",
      "(55, 311)\n",
      "(55, 311)\n",
      "(55, 1866)\n"
     ]
    }
   ],
   "source": [
    "#MOVING AVERAGE using PANDAS\n",
    "by = 5 #stride\n",
    "win = 15 #windows\n",
    "start = 0\n",
    "\n",
    "# IMPUTATION\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "dfqr = pd.DataFrame(imputer.fit_transform(dfqr))\n",
    "dfqr.columns = dfqr.columns\n",
    "\n",
    "# MEAN\n",
    "dfmean = dfqr.rolling(win).mean()[start::by] \n",
    "dfmean = dfmean.dropna(inplace=False)\n",
    "print(dfmean.shape)\n",
    "\n",
    "# MIN\n",
    "dfmin = dfqr.rolling(win).min()[start::by]\n",
    "dfmin = dfmin.dropna(inplace=False)\n",
    "print(dfmin.shape)\n",
    "\n",
    "# MAX\n",
    "dfmax = dfqr.rolling(win).max()[start::by] \n",
    "dfmax = dfmax.dropna(inplace=False)\n",
    "print(dfmax.shape)\n",
    "\n",
    "# STD\n",
    "dfstd = dfqr.rolling(win).std()[start::by]\n",
    "dfstd = dfstd.dropna(inplace=False)\n",
    "print(dfstd.shape)\n",
    "\n",
    "# KURTOSIS\n",
    "# dfkurt = dfqr.rolling(win).kurt()[start::by]\n",
    "# dfkurt = dfkurt.iloc[3:,:]\n",
    "#dfkurt = dfkurt.fillna(0)\n",
    "# print(dfkurt.shape)\n",
    "\n",
    "# SKEWNESS\n",
    "# dfskew = dfqr.rolling(win).skew()[start::by]\n",
    "# dfskew = dfskew.iloc[3:,:]\n",
    "#dfskew = dfskew.fillna(0)\n",
    "#print(dfskew.shape)\n",
    "\n",
    "# MEDIAN\n",
    "dfmed = dfqr.rolling(win).median()[start::by]\n",
    "dfmed = dfmed.dropna()\n",
    "print(dfmed.shape)\n",
    "\n",
    "# CORRELATION\n",
    "dfcorr = dfqr.rolling(win).median()[start::by]\n",
    "dfcorr = dfcorr.dropna()\n",
    "print(dfcorr.shape)\n",
    "\n",
    "# NEW FEATURES\n",
    "dfnew = pd.concat([dfmean,dfmin,dfmax,dfstd, dfmed,dfcorr], axis=1) #,dfkurt,dfskew\n",
    "print(dfnew.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "rows_with_nan = []\n",
    "for  index, row in dfnew.iterrows():\n",
    "    is_nan_series = row.isnull()\n",
    "    if is_nan_series.any():\n",
    "        rows_with_nan.append(index)\n",
    "print(rows_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Missing data\n",
    "# missing_data = dfnew.isnull()\n",
    "# print(missing_data)\n",
    "\n",
    "# Correct data format\n",
    "# print(dfnew.dtypes)\n",
    "\n",
    "#for column in missing_data.columns.values.tolist():\n",
    "#    print(column)\n",
    "#    print (missing_data[column].value_counts())\n",
    "#    print('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAISEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(datapath,labelfile,colnum):\n",
    "    df = pd.read_csv(labelfile) #load label\n",
    "    \n",
    "    #create empty list\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "\n",
    "    by = 10 #stride\n",
    "    win = 20 #windows\n",
    "    start = 0\n",
    "    \n",
    "    for noid, clipid in enumerate(df.ClipID):\n",
    "        temp_df = pd.read_csv(datapath+clipid) \n",
    "        # print(temp_df)\n",
    "\n",
    "        # REMOVE SPACES FROM COLUMN NAMES\n",
    "        temp_df = pd.DataFrame(df_feat)\n",
    "        temp_df.columns = temp_df.columns.str.replace(' ','')\n",
    "        # IMPUTATION\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        imputed_df = pd.DataFrame(imputer.fit_transform(temp_df))\n",
    "        imputed_df.columns = temp_df.columns\n",
    "        # SELECT DATA from TIMESTEPS between 0.5 to 9.5\n",
    "        temp_df = temp_df.query('(timestamp > 0.0) & (timestamp < 10)')\n",
    "        temp_df = temp_df.iloc[:,colnum] #select features \n",
    "\n",
    "        # MOVING AVERAGE (Mean)\n",
    "        dfmean = temp_df.rolling(win).mean()[start::by] \n",
    "        dfmean = dfmean.dropna(inplace=False)\n",
    "        #print(dfmean.shape)\n",
    "        # MIN\n",
    "        dfmin = temp_df.rolling(win).min()[start::by]\n",
    "        dfmin = dfmin.dropna(inplace=False)\n",
    "        #print(dfmin.shape)\n",
    "        # MAX\n",
    "        dfmax = temp_df.rolling(win).max()[start::by] \n",
    "        dfmax = dfmax.dropna(inplace=False)\n",
    "        #print(dfmax.shape)\n",
    "        # STD\n",
    "        dfstd = temp_df.rolling(win).std()[start::by]\n",
    "        dfstd = dfstd.dropna(inplace=False)\n",
    "        #print(dfstd.shape)\n",
    "        # KURTOSIS\n",
    "        # dfkurt = temp_df.rolling(win).kurt()[start::by]\n",
    "        # dfkurt = dfkurt.iloc[3:,:]\n",
    "        # dfkurt = dfkurt.fillna(0)\n",
    "        # print(dfkurt.shape)\n",
    "        # SKEWNESS\n",
    "        # dfskew = temp_df.rolling(win).skew()[start::by]\n",
    "        # dfskew = dfskew.iloc[3:,:]\n",
    "        #dfskew = dfskew.fillna(0)\n",
    "        # print(dfskew.shape)\n",
    "        # MEDIAN\n",
    "        dfmed = temp_df.rolling(win).median()[start::by]\n",
    "        dfmed = dfmed.dropna(inplace=False)\n",
    "        #print(dfmed.shape)\n",
    "        # CORRELATION\n",
    "        dfcorr = temp_df.rolling(win).median()[start::by]\n",
    "        dfcorr = dfcorr.dropna(inplace=False)\n",
    "        #print(dfcorr.shape)\n",
    "\n",
    "        # NEW FEATURES\n",
    "        dfnew = pd.concat([dfmean,dfmin,dfmax,dfstd,dfmed,dfcorr], axis=1)\n",
    "        #print(dfnew.shape)\n",
    "        #print(dfnew)\n",
    "\n",
    "        #imputed = pd.DataFrame(imputer.fit_transform(dfnew))\n",
    "        #print(imputed)\n",
    "        #print(imputed)\n",
    "        #dfnew.columns = imputed.columns\n",
    "        #imputed.columns = dfnew.columns\n",
    "        #print(imputed.print)\n",
    "\n",
    "        data_list.append(dfnew)\n",
    "        labl = df.Engagement[noid] \n",
    "        labl = np.array(labl)\n",
    "        label_list.append(labl)    \n",
    "    \n",
    "    X = np.array(data_list) #features\n",
    "    Y = np.array(label_list) #labels\n",
    "    print('X shape:{}, Y shape:{}'.format(X.shape,Y.shape))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:(5467, 28, 1866), Y shape:(5467,)\n",
      "X shape:(1703, 28, 1866), Y shape:(1703,)\n",
      "X shape:(1782, 28, 1866), Y shape:(1782,)\n",
      "Processing time 0:31:44.355816\n"
     ]
    }
   ],
   "source": [
    "tic = datetime.now()\n",
    "X_train, Y_train = extract(path_daisee+'csv_train/',path_daisee+'labels/TrainLabels.csv',features311)\n",
    "X_val, Y_val = extract(path_daisee+'csv_val/',path_daisee+'labels/ValidationLabels.csv',features311)\n",
    "X_test, Y_test = extract(path_daisee+'csv_test/',path_daisee+'labels/TestLabels.csv',features311)\n",
    "time = datetime.now() - tic\n",
    "print('Processing time {}'.format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE INPUT\n",
    "with open('extracted\\daisee_55_1866.pkl','wb') as f:\n",
    "    pickle.dump([X_train, X_val, X_test, Y_train, Y_val, Y_test], f) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD INPUT\n",
    "with open('extracted\\daisee_28_186.pkl','rb') as f:\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e971d",
   "metadata": {},
   "source": [
    "### Averaged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd295d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaged(set,datapath,labelfile,colnum):\n",
    "    # path = 'C:/Users/hasegawa-lab-pc/OneDrive - Japan Advanced Institute of Science and Technology/Documents/Dataset/DAiSEE/OpenFace_2.2.0_win_x64/processed/csv/'\n",
    "    df = pd.read_csv(labelfile) #load label\n",
    "\n",
    "    feat = []\n",
    "    for noid, clipid in enumerate(df.ClipID):\n",
    "        features = pd.read_csv(datapath+clipid, index_col=None, header=0)\n",
    "        features = features.drop(features.columns[0:5], axis=1)\n",
    "        features = features.mean(axis=0)\n",
    "        #add label in column\n",
    "        label = df.Engagement[noid]\n",
    "        features['Engagement'] = label\n",
    "        features = pd.DataFrame(features).T #transpose after averaging\n",
    "    #     print(features)\n",
    "        feat.append(features)\n",
    "    #     print(feat)\n",
    "    #     break\n",
    "        \n",
    "    average = pd.concat(feat, axis=0, ignore_index=True)\n",
    "    average.to_csv('average_'+set+'_31.csv', header=True)\n",
    "    # print(average)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93b85a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       gaze_0_x   gaze_0_y   gaze_0_z   gaze_1_x   gaze_1_y   gaze_1_z  \\\n",
      "0      0.005156   0.133347  -0.988443  -0.126728   0.152687  -0.976228   \n",
      "1      0.017515   0.130940  -0.989608  -0.113039   0.146805  -0.980789   \n",
      "2     -0.025878   0.082237  -0.995969  -0.139633   0.098979  -0.984932   \n",
      "3      0.040726   0.093319  -0.988113  -0.109170   0.105283  -0.985015   \n",
      "4      0.043953   0.089294  -0.988279  -0.098556   0.021485  -0.990954   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1698   0.039094   0.098567  -0.991039  -0.068902   0.096786  -0.990767   \n",
      "1699   0.073809   0.061387  -0.993835  -0.033212   0.050515  -0.997192   \n",
      "1700   0.089112   0.069037  -0.991515  -0.031849   0.064963  -0.995422   \n",
      "1701   0.037129   0.086772  -0.993738  -0.071466   0.073205  -0.993034   \n",
      "1702   0.112159   0.086659  -0.988219  -0.004172   0.070163  -0.996479   \n",
      "\n",
      "       gaze_angle_x   gaze_angle_y   eye_lmk_x_0   eye_lmk_x_1  ...    AU14_c  \\\n",
      "0         -0.061916       0.144645    334.181605    336.189967  ...  0.120401   \n",
      "1         -0.048552       0.140114    323.022408    324.822074  ...  0.000000   \n",
      "2         -0.083344       0.091258    336.594649    338.533445  ...  0.000000   \n",
      "3         -0.034569       0.100331    310.543813    312.677258  ...  0.000000   \n",
      "4         -0.027575       0.055933    308.691639    310.651505  ...  0.000000   \n",
      "...             ...            ...           ...           ...  ...       ...   \n",
      "1698      -0.015020       0.098280    287.683667    290.190000  ...  1.000000   \n",
      "1699       0.020390       0.056150    281.012667    282.034000  ...  1.000000   \n",
      "1700       0.028770       0.067363    281.451667    282.503667  ...  1.000000   \n",
      "1701      -0.017307       0.080410    278.593667    279.609333  ...  1.000000   \n",
      "1702       0.054420       0.078860    261.765667    263.312333  ...  1.000000   \n",
      "\n",
      "       AU15_c    AU17_c    AU20_c    AU23_c    AU25_c    AU26_c   AU28_c  \\\n",
      "0         0.0  0.023411  0.113712  1.000000  0.026756  0.050167      0.0   \n",
      "1         0.0  0.150502  0.046823  0.963211  0.133779  0.163880      0.0   \n",
      "2         0.0  0.053512  0.000000  1.000000  0.000000  0.000000      0.0   \n",
      "3         0.0  0.073579  0.006689  0.933110  0.023411  0.003344      0.0   \n",
      "4         0.0  0.133779  0.010033  0.829431  0.000000  0.000000      0.0   \n",
      "...       ...       ...       ...       ...       ...       ...      ...   \n",
      "1698      0.0  0.000000  0.000000  0.920000  0.000000  0.000000      0.0   \n",
      "1699      0.0  0.000000  0.000000  0.040000  0.000000  0.000000      0.0   \n",
      "1700      0.0  0.000000  0.000000  0.010000  0.000000  0.000000      0.0   \n",
      "1701      0.0  0.000000  0.000000  0.006667  0.000000  0.000000      0.0   \n",
      "1702      0.0  0.003333  0.000000  0.400000  0.000000  0.000000      0.0   \n",
      "\n",
      "        AU45_c  Engagement  \n",
      "0     0.210702         2.0  \n",
      "1     0.257525         3.0  \n",
      "2     0.147157         2.0  \n",
      "3     0.127090         3.0  \n",
      "4     0.157191         2.0  \n",
      "...        ...         ...  \n",
      "1698  0.186667         2.0  \n",
      "1699  0.156667         2.0  \n",
      "1700  0.133333         2.0  \n",
      "1701  0.053333         3.0  \n",
      "1702  0.053333         2.0  \n",
      "\n",
      "[1703 rows x 330 columns]\n",
      "       gaze_0_x   gaze_0_y   gaze_0_z   gaze_1_x   gaze_1_y   gaze_1_z  \\\n",
      "0      0.003661   0.072152  -0.995901  -0.161883   0.077863  -0.982155   \n",
      "1      0.026855   0.046216  -0.996686  -0.140524   0.052108  -0.987184   \n",
      "2     -0.002622   0.102958  -0.994127  -0.166620   0.104854  -0.979882   \n",
      "3      0.001285   0.101398  -0.994806  -0.163293   0.107472  -0.980673   \n",
      "4     -0.005412   0.117999  -0.992872  -0.157933   0.121057  -0.979884   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1777   0.164802   0.188183  -0.967902  -0.035343   0.139625  -0.989321   \n",
      "1778   0.085811  -0.048283  -0.994399  -0.093669  -0.025742  -0.994640   \n",
      "1779   0.127171  -0.009944  -0.991714  -0.047190  -0.013909  -0.998682   \n",
      "1780   0.128271  -0.016927  -0.991510  -0.058760   0.009401  -0.998169   \n",
      "1781   0.085052  -0.048770  -0.994513  -0.094405  -0.016397  -0.994826   \n",
      "\n",
      "       gaze_angle_x   gaze_angle_y   eye_lmk_x_0   eye_lmk_x_1  ...    AU14_c  \\\n",
      "0         -0.079843       0.075703    334.788000    336.242000  ...  0.686667   \n",
      "1         -0.057150       0.049553    324.216667    325.737000  ...  0.396667   \n",
      "2         -0.085530       0.104893    331.654667    333.124000  ...  0.310000   \n",
      "3         -0.081827       0.105323    328.286333    329.686000  ...  0.043333   \n",
      "4         -0.082633       0.120560    327.701667    329.134667  ...  0.476667   \n",
      "...             ...            ...           ...           ...  ...       ...   \n",
      "1777       0.066030       0.165947    268.821333    271.572000  ...  1.000000   \n",
      "1778      -0.003963      -0.037170    294.399333    296.038333  ...  0.950000   \n",
      "1779       0.040147      -0.011980    281.579667    284.078000  ...  0.000000   \n",
      "1780       0.034907      -0.003750    283.193000    284.887667  ...  0.000000   \n",
      "1781      -0.004690      -0.032743    283.381667    284.810667  ...  0.290000   \n",
      "\n",
      "        AU15_c    AU17_c    AU20_c    AU23_c    AU25_c    AU26_c   AU28_c  \\\n",
      "0     0.160000  0.083333  0.063333  0.883333  0.166667  0.220000      0.0   \n",
      "1     0.053333  0.050000  0.070000  0.673333  0.000000  0.000000      0.0   \n",
      "2     0.046667  0.123333  0.033333  0.956667  0.013333  0.000000      0.0   \n",
      "3     0.026667  0.080000  0.033333  0.996667  0.000000  0.000000      0.0   \n",
      "4     0.123333  0.183333  0.036667  0.876667  0.050000  0.246667      0.0   \n",
      "...        ...       ...       ...       ...       ...       ...      ...   \n",
      "1777  0.000000  0.016667  0.000000  1.000000  0.000000  0.000000      0.0   \n",
      "1778  0.170000  0.193333  0.083333  0.900000  0.006667  0.000000      0.0   \n",
      "1779  0.000000  0.043333  0.000000  1.000000  0.030000  0.000000      0.0   \n",
      "1780  0.000000  0.000000  0.000000  1.000000  0.000000  0.000000      0.0   \n",
      "1781  0.000000  0.166667  0.000000  0.873333  0.000000  0.000000      0.0   \n",
      "\n",
      "        AU45_c  Engagement  \n",
      "0     0.023333         2.0  \n",
      "1     0.120000         2.0  \n",
      "2     0.013333         2.0  \n",
      "3     0.063333         2.0  \n",
      "4     0.063333         2.0  \n",
      "...        ...         ...  \n",
      "1777  0.210000         3.0  \n",
      "1778  0.203333         3.0  \n",
      "1779  0.063333         3.0  \n",
      "1780  0.060000         3.0  \n",
      "1781  0.173333         2.0  \n",
      "\n",
      "[1782 rows x 330 columns]\n",
      "Processing time 0:01:17.807070\n"
     ]
    }
   ],
   "source": [
    "tic = datetime.now()\n",
    "# train = averaged('train',path_daisee+'csv_train/',path_daisee+'labels/TrainLabels.csv',features31)\n",
    "val = averaged('val',path_daisee+'csv_val/',path_daisee+'labels/ValidationLabels.csv',features31)\n",
    "test = averaged('test',path_daisee+'csv_test/',path_daisee+'labels/TestLabels.csv',features31)\n",
    "time = datetime.now() - tic\n",
    "print('Processing time {}'.format(time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMOTIW 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emotiw2018(datapath,colnum):\n",
    "    df = pd.read_csv(path_emotiw+'Labels_Engagement.csv') #load label\n",
    "    id = df.iloc[:,0]\n",
    "    \n",
    "    #create empty list\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "\n",
    "    by = 5 #stride\n",
    "    win = 10 #windows\n",
    "    start = 0\n",
    "    \n",
    "    for noid, clipid in enumerate(id):\n",
    "        temp_df = pd.read_csv(datapath+clipid) \n",
    "        # print(noid, clipid)\n",
    "        # print(temp_df)\n",
    "\n",
    "        # REMOVE SPACES FROM COLUMN NAMES\n",
    "        temp_df = pd.DataFrame(df_feat)\n",
    "        temp_df.columns = temp_df.columns.str.replace(' ','')\n",
    "        # IMPUTATION\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        imputed_df = pd.DataFrame(imputer.fit_transform(temp_df))\n",
    "        imputed_df.columns = temp_df.columns\n",
    "        # SELECT DATA from TIMESTEPS between 30 seconds to 3 minutes 30 secs (210 seconds)\n",
    "        # temp_df = temp_df.query('(timestamp < 200)') #for downsampled\n",
    "        temp_df = temp_df.query('(timestamp > 0.30) & (timestamp < 210)')\n",
    "        temp_df = temp_df.iloc[:,colnum] #select features \n",
    "\n",
    "        # MOVING AVERAGE (Mean)\n",
    "        dfmean = temp_df.rolling(win).mean()[start::by] \n",
    "        dfmean = dfmean.dropna(inplace=False)\n",
    "        # MIN\n",
    "        dfmin = temp_df.rolling(win).min()[start::by]\n",
    "        dfmin = dfmin.dropna(inplace=False)\n",
    "        # MAX\n",
    "        dfmax = temp_df.rolling(win).max()[start::by] \n",
    "        dfmax = dfmax.dropna(inplace=False)\n",
    "        # STD\n",
    "        dfstd = temp_df.rolling(win).std()[start::by]\n",
    "        dfstd = dfstd.dropna(inplace=False)\n",
    "        # # KURTOSIS\n",
    "        # dfkurt = temp_df.rolling(win).kurt()[start::by]\n",
    "        # dfkurt = dfkurt.iloc[3:,:]\n",
    "        # dfkurt = dfkurt.fillna(0)\n",
    "        # # SKEWNESS\n",
    "        # dfskew = temp_df.rolling(win).skew()[start::by]\n",
    "        # dfskew = dfskew.iloc[3:,:]\n",
    "        # dfskew = dfskew.fillna(0)\n",
    "        # MEDIAN\n",
    "        dfmed = temp_df.rolling(win).median()[start::by]\n",
    "        dfmed = dfmed.dropna(inplace=False)\n",
    "        # CORRELATION\n",
    "        dfcorr = temp_df.rolling(win).median()[start::by]\n",
    "        dfcorr = dfcorr.dropna(inplace=False)\n",
    "\n",
    "        # NEW FEATURES\n",
    "        dfnew = pd.concat([dfmean,dfmin,dfmax,dfstd,dfmed,dfcorr], axis=1)\n",
    "        # ,dfkurt,dfskew,\n",
    "\n",
    "        temp_df = np.array(dfnew)\n",
    "        data_list.append(temp_df)\n",
    "        labl = df.iloc[noid,1]  \n",
    "        labl = np.array(labl)\n",
    "        label_list.append(labl)    \n",
    "    \n",
    "    X = np.array(data_list) #features\n",
    "    Y = np.array(label_list) #labels\n",
    "    print('X shape:{}, Y shape:{}'.format(X.shape,Y.shape))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT EMOTIW2018\n",
    "tic = datetime.now()\n",
    "# X, y = load_emotiw2018(path_emotiw+'trainval/',features31)\n",
    "#X, y = load_emotiw2018('C:/Users/hasegawa-lab-pc/OneDrive - Japan Advanced Institute of Science and Technology/Documents/Dataset/EmotiW/Downsampled video/csv/',features31)\n",
    "X, y = load_emotiw2018(path_emotiw+'trainval/',features31)\n",
    "time = datetime.now() - tic\n",
    "print('Processing time {}'.format(time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE INPUT\n",
    "with open('extracted\\emotiw_186.pkl','wb') as f:\n",
    "    pickle.dump([X, y], f) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD INPUT\n",
    "with open('extracted\\emotiw_31_56.pkl','rb') as f:\n",
    "    X, y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape,X_val.shape,X_test.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESHAPE DATA\n",
    "# create one big data panel with n_features series\n",
    "X_reshaped = X.reshape((X.shape[0]*X.shape[1], X.shape[2])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PCA\n",
    "n_comp = 20\n",
    "pca = PCA(n_components=n_comp)\n",
    "pca.fit(X_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = np.empty([X.shape[0],X.shape[1],n_comp])\n",
    "# iteratively apply the transformation to each instance of the original dataset\n",
    "for i in range(len(X)):\n",
    "    X_transformed[i]=pca.transform(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_transformed.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc86f5e1d763e51324beefa3721016490e22711f0b9054847e29143218b2ad33"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('tf2.1': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
